import sys; print('Python %s on %s' % (sys.version, sys.platform))
/home/xunull/anaconda3/bin/conda run -n detrex --no-capture-output python /home/xunull/.pycharm_helpers/pydev/pydevd.py --multiprocess --qt-support=auto --client 127.0.0.1 --port 38645 --file /mnt/d/xunull-repository/others-github/AiGitRepos/group-detection/detrex/tools/train_net.py --config-file projects/focus_detr/configs/focus_detr_resnet/focus_detr_r50_4scale_12ep.py --num-gpus 1
Connected to pydev debugger (build 232.8660.197)
[07/30 14:05:36 detectron2]: Rank of current process: 0. World size: 1
[07/30 14:05:37 detectron2]: Environment info:
----------------------  ---------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.17 (default, Jul  5 2023, 21:04:15) [GCC 11.2.0]
numpy                   1.22.4
detectron2              0.6 @/mnt/d/xunull-repository/others-github/AiGitRepos/group-detection/detrex/detectron2/detectron2
Compiler                GCC 9.4
CUDA compiler           CUDA 11.3
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.12.1+cu113 @/home/xunull/anaconda3/envs/detrex/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3080 (arch=8.6)
GPU 1                   NVIDIA GeForce RTX 3060 (arch=8.6)
Driver version          536.67
CUDA_HOME               /usr/local/cuda
Pillow                  8.4.0
torchvision             0.13.1+cu113 @/home/xunull/anaconda3/envs/detrex/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.6.0
----------------------  ---------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.3.2  (built against CUDA 11.5)
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF,
[07/30 14:05:37 detectron2]: Command line arguments: Namespace(config_file='projects/focus_detr/configs/focus_detr_resnet/focus_detr_r50_4scale_12ep.py', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[07/30 14:05:37 detectron2]: Contents of args.config_file=projects/focus_detr/configs/focus_detr_resnet/focus_detr_r50_4scale_12ep.py:
#Copyright (C) 2023. Huawei Technologies Co., Ltd. All rights reserved.
#This program is free software; you can redistribute it and/or modify it under the terms of the MIT License.
#This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the MIT License for more details.
from detrex.config import get_config
from ..models.focus_detr_r50 import model
# get default config
dataloader = get_config("common/data/coco_detr.py").dataloader
optimizer = get_config("common/optim.py").AdamW
lr_multiplier = get_config("common/coco_schedule.py").lr_multiplier_12ep
train = get_config("common/train.py").train
# modify training config
train.init_checkpoint = "detectron2://ImageNetPretrained/torchvision/R-50.pkl"
# train.init_checkpoint = "./pre-trained/resnet_torch/r50_v1.pkl"
train.output_dir = "./output/focus_detr_r50_4scale_12ep"
# max training iterations
train.max_iter = 90000
train.eval_period = 5000
train.log_period = 20
train.checkpointer.period = 5000
# gradient clipping for training
train.clip_grad.enabled = True
train.clip_grad.params.max_norm = 0.1
train.clip_grad.params.norm_type = 2
# set training devices
train.device = "cuda"
model.device = train.device
# modify optimizer config
optimizer.lr = 1e-4
optimizer.betas = (0.9, 0.999)
optimizer.weight_decay = 1e-4
optimizer.params.lr_factor_func = lambda module_name: 0.1 if "backbone" in module_name else 1
# modify dataloader config
dataloader.train.num_workers = 16
# please notice that this is total batch size.
# surpose you're using 4 gpus for training and the batch size for
# each gpu is 16/4 = 4
dataloader.train.total_batch_size = 1
# dump the testing results into output_dir for visualization
dataloader.evaluator.output_dir = train.output_dir
WARNING [07/30 14:05:38 d2.config.lazy]: The config contains objects that cannot serialize to a valid yaml. ./output/focus_detr_r50_4scale_12ep/config.yaml is human-readable but cannot be loaded.
WARNING [07/30 14:05:38 d2.config.lazy]: Config is saved using cloudpickle at ./output/focus_detr_r50_4scale_12ep/config.yaml.pkl.
[07/30 14:05:38 detectron2]: Full config saved to ./output/focus_detr_r50_4scale_12ep/config.yaml
[07/30 14:05:38 d2.utils.env]: Using a generated random seed 38379257
[07/30 14:05:40 detectron2]: Model:
FOCUS_DETR(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
  )
  (position_embedding): PositionEmbeddingSine()
  (neck): ChannelMapper(
    (convs): ModuleList(
      (0): ConvNormAct(
        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (1): ConvNormAct(
        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (2): ConvNormAct(
        (conv): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (extra_convs): ModuleList(
      (0): ConvNormAct(
        (conv): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
  )
  (transformer): FOCUS_DETRTransformer(
    (encoder): FOCUS_DETRTransformerEncoder(
      (layers): ModuleList(
        (0): Focus_DETR_BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (1): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.0, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=2048, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=2048, out_features=256, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (1): Focus_DETR_BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (1): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.0, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=2048, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=2048, out_features=256, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): Focus_DETR_BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (1): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.0, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=2048, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=2048, out_features=256, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (3): Focus_DETR_BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (1): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.0, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=2048, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=2048, out_features=256, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (4): Focus_DETR_BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (1): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.0, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=2048, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=2048, out_features=256, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): Focus_DETR_BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (1): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.0, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=2048, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=2048, out_features=256, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (enhance_MCSP): ModuleList(
        (0): Linear(in_features=256, out_features=80, bias=True)
        (1): Linear(in_features=256, out_features=80, bias=True)
        (2): Linear(in_features=256, out_features=80, bias=True)
        (3): Linear(in_features=256, out_features=80, bias=True)
        (4): Linear(in_features=256, out_features=80, bias=True)
        (5): Linear(in_features=256, out_features=80, bias=True)
      )
    )
    (decoder): FOCUS_DETRTransformerDecoder(
      (layers): ModuleList(
        (0): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (1): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.0, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=2048, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=2048, out_features=256, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (1): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (1): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.0, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=2048, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=2048, out_features=256, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (2): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (1): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.0, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=2048, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=2048, out_features=256, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (3): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (1): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.0, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=2048, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=2048, out_features=256, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (4): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (1): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.0, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=2048, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=2048, out_features=256, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (5): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (1): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.0, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=2048, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=2048, out_features=256, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (ref_point_head): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=512, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
        )
      )
      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (class_embed): ModuleList(
        (0): Linear(in_features=256, out_features=80, bias=True)
        (1): Linear(in_features=256, out_features=80, bias=True)
        (2): Linear(in_features=256, out_features=80, bias=True)
        (3): Linear(in_features=256, out_features=80, bias=True)
        (4): Linear(in_features=256, out_features=80, bias=True)
        (5): Linear(in_features=256, out_features=80, bias=True)
        (6): Linear(in_features=256, out_features=80, bias=True)
      )
      (bbox_embed): ModuleList(
        (0): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=4, bias=True)
          )
        )
        (1): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=4, bias=True)
          )
        )
        (2): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=4, bias=True)
          )
        )
        (3): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=4, bias=True)
          )
        )
        (4): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=4, bias=True)
          )
        )
        (5): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=4, bias=True)
          )
        )
        (6): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=4, bias=True)
          )
        )
      )
    )
    (tgt_embed): Embedding(900, 256)
    (enc_output): Linear(in_features=256, out_features=256, bias=True)
    (enc_output_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (enc_mask_predictor): MaskPredictor(
      (layer1): Sequential(
        (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (1): Linear(in_features=256, out_features=256, bias=True)
        (2): GELU(approximate=none)
      )
      (layer2): Sequential(
        (0): Linear(in_features=256, out_features=128, bias=True)
        (1): GELU(approximate=none)
        (2): Linear(in_features=128, out_features=64, bias=True)
        (3): GELU(approximate=none)
        (4): Linear(in_features=64, out_features=1, bias=True)
      )
    )
  )
  (class_embed): ModuleList(
    (0): Linear(in_features=256, out_features=80, bias=True)
    (1): Linear(in_features=256, out_features=80, bias=True)
    (2): Linear(in_features=256, out_features=80, bias=True)
    (3): Linear(in_features=256, out_features=80, bias=True)
    (4): Linear(in_features=256, out_features=80, bias=True)
    (5): Linear(in_features=256, out_features=80, bias=True)
    (6): Linear(in_features=256, out_features=80, bias=True)
  )
  (bbox_embed): ModuleList(
    (0): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
    (1): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
    (2): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
    (3): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
    (4): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
    (5): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
    (6): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (criterion): Criterion FOCUS_DETRCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_bbox: 5.0
          cost_giou: 2.0
          cost_class_type: focal_loss_cost
          focal cost alpha: 0.25
          focal cost gamma: 2.0
      losses: ['class', 'boxes']
      loss_class_type: focal_loss
      weight_dict: {'loss_class': 1, 'loss_bbox': 5.0, 'loss_giou': 2.0, 'loss_class_dn': 1, 'loss_bbox_dn': 5.0, 'loss_giou_dn': 2.0, 'loss_class_enc': 1, 'loss_bbox_enc': 5.0, 'loss_giou_enc': 2.0, 'loss_class_dn_enc': 1, 'loss_bbox_dn_enc': 5.0, 'loss_giou_dn_enc': 2.0, 'loss_class_0': 1, 'loss_bbox_0': 5.0, 'loss_giou_0': 2.0, 'loss_class_dn_0': 1, 'loss_bbox_dn_0': 5.0, 'loss_giou_dn_0': 2.0, 'loss_class_1': 1, 'loss_bbox_1': 5.0, 'loss_giou_1': 2.0, 'loss_class_dn_1': 1, 'loss_bbox_dn_1': 5.0, 'loss_giou_dn_1': 2.0, 'loss_class_2': 1, 'loss_bbox_2': 5.0, 'loss_giou_2': 2.0, 'loss_class_dn_2': 1, 'loss_bbox_dn_2': 5.0, 'loss_giou_dn_2': 2.0, 'loss_class_3': 1, 'loss_bbox_3': 5.0, 'loss_giou_3': 2.0, 'loss_class_dn_3': 1, 'loss_bbox_dn_3': 5.0, 'loss_giou_dn_3': 2.0, 'loss_class_4': 1, 'loss_bbox_4': 5.0, 'loss_giou_4': 2.0, 'loss_class_dn_4': 1, 'loss_bbox_dn_4': 5.0, 'loss_giou_dn_4': 2.0, 'select_loss': 1.5}
      num_classes: 80
      eos_coef: None
      focal loss alpha: 0.25
      focal loss gamma: 2.0
  (label_enc): Embedding(80, 256)
  (enhance_MCSP_layerlist): ModuleList(
    (0): Linear(in_features=256, out_features=80, bias=True)
    (1): Linear(in_features=256, out_features=80, bias=True)
    (2): Linear(in_features=256, out_features=80, bias=True)
    (3): Linear(in_features=256, out_features=80, bias=True)
    (4): Linear(in_features=256, out_features=80, bias=True)
    (5): Linear(in_features=256, out_features=80, bias=True)
  )
)
[07/30 14:05:52 d2.data.datasets.coco]: Loading /mnt/h/ml_dataset_home/coco/annotations/instances_train2017.json takes 12.08 seconds.
[07/30 14:05:53 d2.data.datasets.coco]: Loaded 118287 images in COCO format from /mnt/h/ml_dataset_home/coco/annotations/instances_train2017.json
[07/30 14:06:01 d2.data.build]: Removed 1021 images with no usable annotations. 117266 images left.
[07/30 14:06:08 d2.data.build]: Distribution of instances among all 80 categories:
|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 257253       |   bicycle    | 7056         |      car      | 43533        |
|  motorcycle   | 8654         |   airplane   | 5129         |      bus      | 6061         |
|     train     | 4570         |    truck     | 9970         |     boat      | 10576        |
| traffic light | 12842        | fire hydrant | 1865         |   stop sign   | 1983         |
| parking meter | 1283         |    bench     | 9820         |     bird      | 10542        |
|      cat      | 4766         |     dog      | 5500         |     horse     | 6567         |
|     sheep     | 9223         |     cow      | 8014         |   elephant    | 5484         |
|     bear      | 1294         |    zebra     | 5269         |    giraffe    | 5128         |
|   backpack    | 8714         |   umbrella   | 11265        |    handbag    | 12342        |
|      tie      | 6448         |   suitcase   | 6112         |    frisbee    | 2681         |
|     skis      | 6623         |  snowboard   | 2681         |  sports ball  | 6299         |
|     kite      | 8802         | baseball bat | 3273         | baseball gl.. | 3747         |
|  skateboard   | 5536         |  surfboard   | 6095         | tennis racket | 4807         |
|    bottle     | 24070        |  wine glass  | 7839         |      cup      | 20574        |
|     fork      | 5474         |    knife     | 7760         |     spoon     | 6159         |
|     bowl      | 14323        |    banana    | 9195         |     apple     | 5776         |
|   sandwich    | 4356         |    orange    | 6302         |   broccoli    | 7261         |
|    carrot     | 7758         |   hot dog    | 2884         |     pizza     | 5807         |
|     donut     | 7005         |     cake     | 6296         |     chair     | 38073        |
|     couch     | 5779         | potted plant | 8631         |      bed      | 4192         |
| dining table  | 15695        |    toilet    | 4149         |      tv       | 5803         |
|    laptop     | 4960         |    mouse     | 2261         |    remote     | 5700         |
|   keyboard    | 2854         |  cell phone  | 6422         |   microwave   | 1672         |
|     oven      | 3334         |   toaster    | 225          |     sink      | 5609         |
| refrigerator  | 2634         |     book     | 24077        |     clock     | 6320         |
|     vase      | 6577         |   scissors   | 1464         |  teddy bear   | 4729         |
|  hair drier   | 198          |  toothbrush  | 1945         |               |              |
|     total     | 849949       |              |              |               |              |
[07/30 14:06:08 d2.data.common]: Serializing 117266 elements to byte tensors and concatenating them all ...
[07/30 14:06:10 d2.data.common]: Serialized dataset takes 452.78 MiB
[07/30 14:06:12 fvcore.common.checkpoint]: [Checkpointer] Loading from detectron2://ImageNetPretrained/torchvision/R-50.pkl ...
[07/30 14:06:12 fvcore.common.checkpoint]: Reading a file from 'torchvision'
[07/30 14:06:12 d2.checkpoint.c2_model_loading]: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint                                                               | Shapes                                          |
|:------------------|:----------------------------------------------------------------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.*      | stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |
WARNING [07/30 14:06:12 fvcore.common.checkpoint]: Some model parameters or buffers are not found in the checkpoint:
bbox_embed.0.layers.0.{bias, weight}
bbox_embed.0.layers.1.{bias, weight}
bbox_embed.0.layers.2.{bias, weight}
bbox_embed.1.layers.0.{bias, weight}
bbox_embed.1.layers.1.{bias, weight}
bbox_embed.1.layers.2.{bias, weight}
bbox_embed.2.layers.0.{bias, weight}
bbox_embed.2.layers.1.{bias, weight}
bbox_embed.2.layers.2.{bias, weight}
bbox_embed.3.layers.0.{bias, weight}
bbox_embed.3.layers.1.{bias, weight}
bbox_embed.3.layers.2.{bias, weight}
bbox_embed.4.layers.0.{bias, weight}
bbox_embed.4.layers.1.{bias, weight}
bbox_embed.4.layers.2.{bias, weight}
bbox_embed.5.layers.0.{bias, weight}
bbox_embed.5.layers.1.{bias, weight}
bbox_embed.5.layers.2.{bias, weight}
bbox_embed.6.layers.0.{bias, weight}
bbox_embed.6.layers.1.{bias, weight}
bbox_embed.6.layers.2.{bias, weight}
class_embed.0.{bias, weight}
class_embed.1.{bias, weight}
class_embed.2.{bias, weight}
class_embed.3.{bias, weight}
class_embed.4.{bias, weight}
class_embed.5.{bias, weight}
class_embed.6.{bias, weight}
enhance_MCSP_layerlist.0.{bias, weight}
enhance_MCSP_layerlist.1.{bias, weight}
enhance_MCSP_layerlist.2.{bias, weight}
enhance_MCSP_layerlist.3.{bias, weight}
enhance_MCSP_layerlist.4.{bias, weight}
enhance_MCSP_layerlist.5.{bias, weight}
label_enc.weight
neck.convs.0.conv.{bias, weight}
neck.convs.0.norm.{bias, weight}
neck.convs.1.conv.{bias, weight}
neck.convs.1.norm.{bias, weight}
neck.convs.2.conv.{bias, weight}
neck.convs.2.norm.{bias, weight}
neck.extra_convs.0.conv.{bias, weight}
neck.extra_convs.0.norm.{bias, weight}
transformer.decoder.bbox_embed.0.layers.0.{bias, weight}
transformer.decoder.bbox_embed.0.layers.1.{bias, weight}
transformer.decoder.bbox_embed.0.layers.2.{bias, weight}
transformer.decoder.bbox_embed.1.layers.0.{bias, weight}
transformer.decoder.bbox_embed.1.layers.1.{bias, weight}
transformer.decoder.bbox_embed.1.layers.2.{bias, weight}
transformer.decoder.bbox_embed.2.layers.0.{bias, weight}
transformer.decoder.bbox_embed.2.layers.1.{bias, weight}
transformer.decoder.bbox_embed.2.layers.2.{bias, weight}
transformer.decoder.bbox_embed.3.layers.0.{bias, weight}
transformer.decoder.bbox_embed.3.layers.1.{bias, weight}
transformer.decoder.bbox_embed.3.layers.2.{bias, weight}
transformer.decoder.bbox_embed.4.layers.0.{bias, weight}
transformer.decoder.bbox_embed.4.layers.1.{bias, weight}
transformer.decoder.bbox_embed.4.layers.2.{bias, weight}
transformer.decoder.bbox_embed.5.layers.0.{bias, weight}
transformer.decoder.bbox_embed.5.layers.1.{bias, weight}
transformer.decoder.bbox_embed.5.layers.2.{bias, weight}
transformer.decoder.bbox_embed.6.layers.0.{bias, weight}
transformer.decoder.bbox_embed.6.layers.1.{bias, weight}
transformer.decoder.bbox_embed.6.layers.2.{bias, weight}
transformer.decoder.class_embed.0.{bias, weight}
transformer.decoder.class_embed.1.{bias, weight}
transformer.decoder.class_embed.2.{bias, weight}
transformer.decoder.class_embed.3.{bias, weight}
transformer.decoder.class_embed.4.{bias, weight}
transformer.decoder.class_embed.5.{bias, weight}
transformer.decoder.class_embed.6.{bias, weight}
transformer.decoder.layers.0.attentions.0.attn.out_proj.{bias, weight}
transformer.decoder.layers.0.attentions.0.attn.{in_proj_bias, in_proj_weight}
transformer.decoder.layers.0.attentions.1.attention_weights.{bias, weight}
transformer.decoder.layers.0.attentions.1.output_proj.{bias, weight}
transformer.decoder.layers.0.attentions.1.sampling_offsets.{bias, weight}
transformer.decoder.layers.0.attentions.1.value_proj.{bias, weight}
transformer.decoder.layers.0.ffns.0.layers.0.0.{bias, weight}
transformer.decoder.layers.0.ffns.0.layers.1.{bias, weight}
transformer.decoder.layers.0.norms.0.{bias, weight}
transformer.decoder.layers.0.norms.1.{bias, weight}
transformer.decoder.layers.0.norms.2.{bias, weight}
transformer.decoder.layers.1.attentions.0.attn.out_proj.{bias, weight}
transformer.decoder.layers.1.attentions.0.attn.{in_proj_bias, in_proj_weight}
transformer.decoder.layers.1.attentions.1.attention_weights.{bias, weight}
transformer.decoder.layers.1.attentions.1.output_proj.{bias, weight}
transformer.decoder.layers.1.attentions.1.sampling_offsets.{bias, weight}
transformer.decoder.layers.1.attentions.1.value_proj.{bias, weight}
transformer.decoder.layers.1.ffns.0.layers.0.0.{bias, weight}
transformer.decoder.layers.1.ffns.0.layers.1.{bias, weight}
transformer.decoder.layers.1.norms.0.{bias, weight}
transformer.decoder.layers.1.norms.1.{bias, weight}
transformer.decoder.layers.1.norms.2.{bias, weight}
transformer.decoder.layers.2.attentions.0.attn.out_proj.{bias, weight}
transformer.decoder.layers.2.attentions.0.attn.{in_proj_bias, in_proj_weight}
transformer.decoder.layers.2.attentions.1.attention_weights.{bias, weight}
transformer.decoder.layers.2.attentions.1.output_proj.{bias, weight}
transformer.decoder.layers.2.attentions.1.sampling_offsets.{bias, weight}
transformer.decoder.layers.2.attentions.1.value_proj.{bias, weight}
transformer.decoder.layers.2.ffns.0.layers.0.0.{bias, weight}
transformer.decoder.layers.2.ffns.0.layers.1.{bias, weight}
transformer.decoder.layers.2.norms.0.{bias, weight}
transformer.decoder.layers.2.norms.1.{bias, weight}
transformer.decoder.layers.2.norms.2.{bias, weight}
transformer.decoder.layers.3.attentions.0.attn.out_proj.{bias, weight}
transformer.decoder.layers.3.attentions.0.attn.{in_proj_bias, in_proj_weight}
transformer.decoder.layers.3.attentions.1.attention_weights.{bias, weight}
transformer.decoder.layers.3.attentions.1.output_proj.{bias, weight}
transformer.decoder.layers.3.attentions.1.sampling_offsets.{bias, weight}
transformer.decoder.layers.3.attentions.1.value_proj.{bias, weight}
transformer.decoder.layers.3.ffns.0.layers.0.0.{bias, weight}
transformer.decoder.layers.3.ffns.0.layers.1.{bias, weight}
transformer.decoder.layers.3.norms.0.{bias, weight}
transformer.decoder.layers.3.norms.1.{bias, weight}
transformer.decoder.layers.3.norms.2.{bias, weight}
transformer.decoder.layers.4.attentions.0.attn.out_proj.{bias, weight}
transformer.decoder.layers.4.attentions.0.attn.{in_proj_bias, in_proj_weight}
transformer.decoder.layers.4.attentions.1.attention_weights.{bias, weight}
transformer.decoder.layers.4.attentions.1.output_proj.{bias, weight}
transformer.decoder.layers.4.attentions.1.sampling_offsets.{bias, weight}
transformer.decoder.layers.4.attentions.1.value_proj.{bias, weight}
transformer.decoder.layers.4.ffns.0.layers.0.0.{bias, weight}
transformer.decoder.layers.4.ffns.0.layers.1.{bias, weight}
transformer.decoder.layers.4.norms.0.{bias, weight}
transformer.decoder.layers.4.norms.1.{bias, weight}
transformer.decoder.layers.4.norms.2.{bias, weight}
transformer.decoder.layers.5.attentions.0.attn.out_proj.{bias, weight}
transformer.decoder.layers.5.attentions.0.attn.{in_proj_bias, in_proj_weight}
transformer.decoder.layers.5.attentions.1.attention_weights.{bias, weight}
transformer.decoder.layers.5.attentions.1.output_proj.{bias, weight}
transformer.decoder.layers.5.attentions.1.sampling_offsets.{bias, weight}
transformer.decoder.layers.5.attentions.1.value_proj.{bias, weight}
transformer.decoder.layers.5.ffns.0.layers.0.0.{bias, weight}
transformer.decoder.layers.5.ffns.0.layers.1.{bias, weight}
transformer.decoder.layers.5.norms.0.{bias, weight}
transformer.decoder.layers.5.norms.1.{bias, weight}
transformer.decoder.layers.5.norms.2.{bias, weight}
transformer.decoder.norm.{bias, weight}
transformer.decoder.ref_point_head.layers.0.{bias, weight}
transformer.decoder.ref_point_head.layers.1.{bias, weight}
transformer.enc_mask_predictor.layer1.0.{bias, weight}
transformer.enc_mask_predictor.layer1.1.{bias, weight}
transformer.enc_mask_predictor.layer2.0.{bias, weight}
transformer.enc_mask_predictor.layer2.2.{bias, weight}
transformer.enc_mask_predictor.layer2.4.{bias, weight}
transformer.enc_output.{bias, weight}
transformer.enc_output_norm.{bias, weight}
transformer.encoder.enhance_MCSP.0.{bias, weight}
transformer.encoder.enhance_MCSP.1.{bias, weight}
transformer.encoder.enhance_MCSP.2.{bias, weight}
transformer.encoder.enhance_MCSP.3.{bias, weight}
transformer.encoder.enhance_MCSP.4.{bias, weight}
transformer.encoder.enhance_MCSP.5.{bias, weight}
transformer.encoder.layers.0.attentions.0.attn.out_proj.{bias, weight}
transformer.encoder.layers.0.attentions.0.attn.{in_proj_bias, in_proj_weight}
transformer.encoder.layers.0.attentions.1.attention_weights.{bias, weight}
transformer.encoder.layers.0.attentions.1.output_proj.{bias, weight}
transformer.encoder.layers.0.attentions.1.sampling_offsets.{bias, weight}
transformer.encoder.layers.0.attentions.1.value_proj.{bias, weight}
transformer.encoder.layers.0.ffns.0.layers.0.0.{bias, weight}
transformer.encoder.layers.0.ffns.0.layers.1.{bias, weight}
transformer.encoder.layers.0.norm2.{bias, weight}
transformer.encoder.layers.0.norms.0.{bias, weight}
transformer.encoder.layers.0.norms.1.{bias, weight}
transformer.encoder.layers.1.attentions.0.attn.out_proj.{bias, weight}
transformer.encoder.layers.1.attentions.0.attn.{in_proj_bias, in_proj_weight}
transformer.encoder.layers.1.attentions.1.attention_weights.{bias, weight}
transformer.encoder.layers.1.attentions.1.output_proj.{bias, weight}
transformer.encoder.layers.1.attentions.1.sampling_offsets.{bias, weight}
transformer.encoder.layers.1.attentions.1.value_proj.{bias, weight}
transformer.encoder.layers.1.ffns.0.layers.0.0.{bias, weight}
transformer.encoder.layers.1.ffns.0.layers.1.{bias, weight}
transformer.encoder.layers.1.norm2.{bias, weight}
transformer.encoder.layers.1.norms.0.{bias, weight}
transformer.encoder.layers.1.norms.1.{bias, weight}
transformer.encoder.layers.2.attentions.0.attn.out_proj.{bias, weight}
transformer.encoder.layers.2.attentions.0.attn.{in_proj_bias, in_proj_weight}
transformer.encoder.layers.2.attentions.1.attention_weights.{bias, weight}
transformer.encoder.layers.2.attentions.1.output_proj.{bias, weight}
transformer.encoder.layers.2.attentions.1.sampling_offsets.{bias, weight}
transformer.encoder.layers.2.attentions.1.value_proj.{bias, weight}
transformer.encoder.layers.2.ffns.0.layers.0.0.{bias, weight}
transformer.encoder.layers.2.ffns.0.layers.1.{bias, weight}
transformer.encoder.layers.2.norm2.{bias, weight}
transformer.encoder.layers.2.norms.0.{bias, weight}
transformer.encoder.layers.2.norms.1.{bias, weight}
transformer.encoder.layers.3.attentions.0.attn.out_proj.{bias, weight}
transformer.encoder.layers.3.attentions.0.attn.{in_proj_bias, in_proj_weight}
transformer.encoder.layers.3.attentions.1.attention_weights.{bias, weight}
transformer.encoder.layers.3.attentions.1.output_proj.{bias, weight}
transformer.encoder.layers.3.attentions.1.sampling_offsets.{bias, weight}
transformer.encoder.layers.3.attentions.1.value_proj.{bias, weight}
transformer.encoder.layers.3.ffns.0.layers.0.0.{bias, weight}
transformer.encoder.layers.3.ffns.0.layers.1.{bias, weight}
transformer.encoder.layers.3.norm2.{bias, weight}
transformer.encoder.layers.3.norms.0.{bias, weight}
transformer.encoder.layers.3.norms.1.{bias, weight}
transformer.encoder.layers.4.attentions.0.attn.out_proj.{bias, weight}
transformer.encoder.layers.4.attentions.0.attn.{in_proj_bias, in_proj_weight}
transformer.encoder.layers.4.attentions.1.attention_weights.{bias, weight}
transformer.encoder.layers.4.attentions.1.output_proj.{bias, weight}
transformer.encoder.layers.4.attentions.1.sampling_offsets.{bias, weight}
transformer.encoder.layers.4.attentions.1.value_proj.{bias, weight}
transformer.encoder.layers.4.ffns.0.layers.0.0.{bias, weight}
transformer.encoder.layers.4.ffns.0.layers.1.{bias, weight}
transformer.encoder.layers.4.norm2.{bias, weight}
transformer.encoder.layers.4.norms.0.{bias, weight}
transformer.encoder.layers.4.norms.1.{bias, weight}
transformer.encoder.layers.5.attentions.0.attn.out_proj.{bias, weight}
transformer.encoder.layers.5.attentions.0.attn.{in_proj_bias, in_proj_weight}
transformer.encoder.layers.5.attentions.1.attention_weights.{bias, weight}
transformer.encoder.layers.5.attentions.1.output_proj.{bias, weight}
transformer.encoder.layers.5.attentions.1.sampling_offsets.{bias, weight}
transformer.encoder.layers.5.attentions.1.value_proj.{bias, weight}
transformer.encoder.layers.5.ffns.0.layers.0.0.{bias, weight}
transformer.encoder.layers.5.ffns.0.layers.1.{bias, weight}
transformer.encoder.layers.5.norm2.{bias, weight}
transformer.encoder.layers.5.norms.0.{bias, weight}
transformer.encoder.layers.5.norms.1.{bias, weight}
transformer.tgt_embed.weight
transformer.{alpha, level_embeds}
WARNING [07/30 14:06:12 fvcore.common.checkpoint]: The checkpoint state_dict contains keys that are not used by the model:
  stem.fc.{bias, weight}
[07/30 14:06:12 d2.engine.train_loop]: Starting training from iteration 0
Error loading: /home/xunull/.pycharm_helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
Error loading: /home/xunull/.pycharm_helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
Error loading: /home/xunull/.pycharm_helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
Error loading: /home/xunull/.pycharm_helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
Error loading: /home/xunull/.pycharm_helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
Error loading: /home/xunull/.pycharm_helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
Error loading: /home/xunull/.pycharm_helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
Error loading: /home/xunull/.pycharm_helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
Error loading: /home/xunull/.pycharm_helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
Error loading: /home/xunull/.pycharm_helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
Error loading: /home/xunull/.pycharm_helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
Error loading: /home/xunull/.pycharm_helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
Error loading: /home/xunull/.pycharm_helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
Error loading: /home/xunull/.pycharm_helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
Error loading: /home/xunull/.pycharm_helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
Error loading: /home/xunull/.pycharm_helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
/home/xunull/anaconda3/envs/detrex/lib/python3.8/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
[07/30 14:06:23 d2.utils.events]:  eta: 8:55:19  iter: 19  total_loss: 64.51  loss_class: 1.31  loss_bbox: 1.613  loss_giou: 1.302  select_loss: 1.868  loss_class_0: 1.144  loss_bbox_0: 1.772  loss_giou_0: 1.324  loss_class_1: 1.141  loss_bbox_1: 1.673  loss_giou_1: 1.303  loss_class_2: 1.195  loss_bbox_2: 1.633  loss_giou_2: 1.301  loss_class_3: 1.217  loss_bbox_3: 1.625  loss_giou_3: 1.304  loss_class_4: 1.201  loss_bbox_4: 1.618  loss_giou_4: 1.304  loss_class_enc: 1.093  loss_bbox_enc: 1.647  loss_giou_enc: 1.341  loss_class_dn: 1.078  loss_bbox_dn: 1.571  loss_giou_dn: 1.287  loss_class_dn_0: 1.035  loss_bbox_dn_0: 1.561  loss_giou_dn_0: 1.286  loss_class_dn_1: 1.039  loss_bbox_dn_1: 1.563  loss_giou_dn_1: 1.286  loss_class_dn_2: 1.054  loss_bbox_dn_2: 1.565  loss_giou_dn_2: 1.286  loss_class_dn_3: 1.078  loss_bbox_dn_3: 1.567  loss_giou_dn_3: 1.286  loss_class_dn_4: 1.109  loss_bbox_dn_4: 1.568  loss_giou_dn_4: 1.286  time: 0.3600  data_time: 0.0237  lr: 0.0001  max_mem: 3374M
[07/30 14:06:30 d2.utils.events]:  eta: 8:56:35  iter: 39  total_loss: 50.22  loss_class: 1.076  loss_bbox: 1.255  loss_giou: 1.124  select_loss: 0.5573  loss_class_0: 1.034  loss_bbox_0: 1.54  loss_giou_0: 1.274  loss_class_1: 1  loss_bbox_1: 1.449  loss_giou_1: 1.225  loss_class_2: 1.076  loss_bbox_2: 1.362  loss_giou_2: 1.205  loss_class_3: 1.087  loss_bbox_3: 1.317  loss_giou_3: 1.189  loss_class_4: 1.087  loss_bbox_4: 1.289  loss_giou_4: 1.153  loss_class_enc: 0.9746  loss_bbox_enc: 1.496  loss_giou_enc: 1.238  loss_class_dn: 0.9699  loss_bbox_dn: 1.648  loss_giou_dn: 1.31  loss_class_dn_0: 0.7886  loss_bbox_dn_0: 1.543  loss_giou_dn_0: 1.301  loss_class_dn_1: 0.8243  loss_bbox_dn_1: 1.528  loss_giou_dn_1: 1.292  loss_class_dn_2: 0.9178  loss_bbox_dn_2: 1.528  loss_giou_dn_2: 1.272  loss_class_dn_3: 0.9311  loss_bbox_dn_3: 1.558  loss_giou_dn_3: 1.282  loss_class_dn_4: 0.925  loss_bbox_dn_4: 1.599  loss_giou_dn_4: 1.296  time: 0.3668  data_time: 0.0013  lr: 0.0001  max_mem: 3547M
